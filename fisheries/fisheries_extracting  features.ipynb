{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(2016)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import log_loss\n",
    "from keras import __version__ as keras_version\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import pdb\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from sklearn import linear_model,decomposition\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score,r2_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "import scipy\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression,SGDClassifier\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "\n",
    "from scipy.sparse import coo_matrix, hstack ,vstack\n",
    "\n",
    "import gc\n",
    "\n",
    "print(gc.collect())\n",
    "\n",
    "import xgboost as xgb\n",
    "from keras import applications\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Listallimages=[]\n",
    "ALB_path='inputdata/train/ALB'\n",
    "BET_path='inputdata/train/BET'\n",
    "DOL_path='inputdata/train/DOL'\n",
    "LAG_path='inputdata/train/LAG'\n",
    "SHARK_path='inputdata/train/SHARK'\n",
    "YFT_path='inputdata/train/YFT'\n",
    "NoF_path = 'inputdata/train/NoF'\n",
    "OTHER_path = 'inputdata/train/OTHER'\n",
    "\n",
    "\n",
    "images=os.listdir(ALB_path)\n",
    "ALB_images=[ff for ff in images if '.jpg' in ff ]\n",
    "\n",
    "\n",
    "images=os.listdir(BET_path)\n",
    "BET_images=[ff for ff in images if '.jpg' in ff ]\n",
    "\n",
    "images=os.listdir(DOL_path)\n",
    "DOL_images=[ff for ff in images if '.jpg' in ff ]\n",
    "\n",
    "images=os.listdir(LAG_path)\n",
    "LAG_images=[ff for ff in images if '.jpg' in ff ]\n",
    "\n",
    "images=os.listdir(SHARK_path)\n",
    "SHARK_images=[ff for ff in images if '.jpg' in ff ]\n",
    "\n",
    "images=os.listdir(YFT_path)\n",
    "YFT_images=[ff for ff in images if '.jpg' in ff ]\n",
    "\n",
    "images=os.listdir(NoF_path)\n",
    "NoF_images=[ff for ff in images if '.jpg' in ff ]\n",
    "\n",
    "images=os.listdir(OTHER_path)\n",
    "OTHER_images=[ff for ff in images if '.jpg' in ff ]\n",
    "\n",
    "Allimages={'ALB': ALB_images,\n",
    "           'BET': BET_images,\n",
    "           'DOL': DOL_images,\n",
    "           'LAG': LAG_images,\n",
    "           'SHARK': SHARK_images,\n",
    "           'YFT': YFT_images,\n",
    "           'NoF': NoF_images,\n",
    "           'OTHER': OTHER_images}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting the mean of red blue and green pixel over all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YFT\n",
      "SHARK\n",
      "OTHER\n",
      "DOL\n",
      "NoF\n",
      "LAG\n",
      "ALB\n",
      "BET\n",
      "(96.403686592621185, 107.12191881841852, 99.894691938946167)\n"
     ]
    }
   ],
   "source": [
    "mean_R = []\n",
    "mean_G = []\n",
    "mean_B = []\n",
    "\n",
    "#loading images\n",
    "for imageset in Allimages.keys():\n",
    "    print imageset\n",
    "    for i in Allimages[imageset]:\n",
    "        img_path = 'inputdata/train/'+imageset+'/'+i\n",
    "        img = image.load_img(img_path, target_size=(224, 224,3))\n",
    "        \n",
    "        #converting images to arrays\n",
    "        x = image.img_to_array(img)\n",
    "        \n",
    "        #finding the mean image\n",
    "        a = np.mean(x[:,:,0])\n",
    "        mean_R = np.append(mean_R,a)\n",
    "        b = np.mean(x[:,:,1])\n",
    "        mean_G = np.append(mean_G,b)\n",
    "        c = np.mean(x[:,:,2])\n",
    "        mean_B = np.append(mean_B,c)\n",
    "\n",
    "#Mean Image\n",
    "I_R = np.mean(mean_R)\n",
    "I_G = np.mean(mean_G)\n",
    "I_B = np.mean(mean_B)\n",
    "print (I_R,I_G,I_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YFT\n",
      "SHARK\n",
      "OTHER\n",
      "DOL\n",
      "NoF\n",
      "LAG\n",
      "ALB\n",
      "BET\n",
      "3777\n"
     ]
    }
   ],
   "source": [
    "Xtrain_resnet50=[]\n",
    "Ytrain_resnet50=[]\n",
    "count = 0\n",
    "Y_top10 = {}\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "\n",
    "#creating normalized image data set\n",
    "for imageset in Allimages.keys():\n",
    "    print imageset\n",
    "    for i in Allimages[imageset]:\n",
    "        img_path = 'inputdata/train/'+imageset+'/'+i\n",
    "        img = image.load_img(img_path, target_size=(224, 224,3))\n",
    "        \n",
    "        x = image.img_to_array(img)\n",
    "        x[:,:,0] = x[:,:,0] - I_R\n",
    "        x[:,:,1] = x[:,:,1] - I_G\n",
    "        x[:,:,2] = x[:,:,2] - I_B\n",
    "    \n",
    "\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "#       x = preprocess_input(x)\n",
    "\n",
    "        preds = model.predict(x)\n",
    "        Xtrain_resnet50.append(preds)\n",
    "        Ytrain_resnet50.append(imageset)\n",
    "\n",
    "        #decode predictions    \n",
    "        Y_top10[i] = decode_predictions(preds,top=10)\n",
    "        count += 1\n",
    "\n",
    "#number of images processed\n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain_resnet50=np.array(Xtrain_resnet50)\n",
    "Ytrain_resnet50=np.array(Ytrain_resnet50)\n",
    "Xtrain_resnet50.shape\n",
    "\n",
    "Xtrain_resnet50=Xtrain_resnet50.reshape(3777,1000)\n",
    "np.savez('ResnetFeatueExtact',Xtrain_resnet50=Xtrain_resnet50,Ytrain_resnet50=Ytrain_resnet50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YFT\n",
      "SHARK\n",
      "OTHER\n",
      "DOL\n",
      "NoF\n",
      "LAG\n",
      "ALB\n",
      "BET\n",
      "3777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3777, 1, 1000)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "Xtrain_VGG16=[]\n",
    "Ytrain_VGG16=[]\n",
    "count = 0\n",
    "Y_top10_VGG16 = {}\n",
    "\n",
    "# from keras.applications.resnet50 import ResNet50\n",
    "# from keras.preprocessing import image\n",
    "# from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "# import numpy as np\n",
    "# model = ResNet50(weights='imagenet')\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=True)\n",
    "\n",
    "\n",
    "#creating normalized image data set\n",
    "for imageset in Allimages.keys():\n",
    "    print imageset\n",
    "    for i in Allimages[imageset]:\n",
    "        img_path = 'inputdata/train/'+imageset+'/'+i\n",
    "        img = image.load_img(img_path, target_size=(224, 224,3))\n",
    "        \n",
    "        x = image.img_to_array(img)\n",
    "        x[:,:,0] = x[:,:,0] - I_R\n",
    "        x[:,:,1] = x[:,:,1] - I_G\n",
    "        x[:,:,2] = x[:,:,2] - I_B\n",
    "    \n",
    "\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "#       x = preprocess_input(x)\n",
    "\n",
    "        preds = model.predict(x)\n",
    "        Xtrain_VGG16.append(preds)\n",
    "        Ytrain_VGG16.append(imageset)\n",
    "\n",
    "        #decode predictions    \n",
    "        Y_top10_VGG16[i] = decode_predictions(preds,top=10)\n",
    "        count += 1\n",
    "\n",
    "#number of images processed\n",
    "print count\n",
    "\n",
    "Xtrain_VGG16=np.array(Xtrain_VGG16)\n",
    "Ytrain_VGG16=np.array(Ytrain_VGG16)\n",
    "Xtrain_VGG16.shape\n",
    "# img_path = 'inputdata/train/SHARK/img_00072.jpg'\n",
    "# img = image.load_img(img_path, target_size=(224, 224,3))\n",
    "# x = image.img_to_array(img)\n",
    "\n",
    "# x = np.expand_dims(x, axis=0)\n",
    "# # x = preprocess_input(x)\n",
    "\n",
    "# features = model.predict(x)\n",
    "# print features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain_VGG16=np.array(Xtrain_VGG16)\n",
    "Ytrain_VGG16=np.array(Ytrain_VGG16)\n",
    "Xtrain_VGG16.shape\n",
    "\n",
    "Xtrain_VGG16=Xtrain_VGG16.reshape(3777,1000)\n",
    "np.savez('VGG16FeatueExtact',Xtrain_VGG16=Xtrain_VGG16,Ytrain_VGG16=Ytrain_VGG16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YFT\n",
      "SHARK\n",
      "OTHER\n",
      "DOL\n",
      "NoF\n",
      "LAG\n",
      "ALB\n",
      "BET\n",
      "3777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3777, 1, 1000)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import preprocess_input, decode_predictions\n",
    "# from keras.models import Model\n",
    "import numpy as np\n",
    "Xtrain_VGG19=[]\n",
    "Ytrain_VGG19=[]\n",
    "count = 0\n",
    "Y_top10_VGG19 = {}\n",
    "\n",
    "model = VGG19(weights='imagenet',include_top=True)\n",
    "# model = Model(input=base_model.input, output=base_model.get_layer('block4_pool').output)\n",
    "\n",
    "#creating normalized image data set\n",
    "for imageset in Allimages.keys():\n",
    "    print imageset\n",
    "    for i in Allimages[imageset]:\n",
    "        img_path = 'inputdata/train/'+imageset+'/'+i\n",
    "        img = image.load_img(img_path, target_size=(224, 224,3))\n",
    "        \n",
    "        x = image.img_to_array(img)\n",
    "        x[:,:,0] = x[:,:,0] - I_R\n",
    "        x[:,:,1] = x[:,:,1] - I_G\n",
    "        x[:,:,2] = x[:,:,2] - I_B\n",
    "    \n",
    "\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "#       x = preprocess_input(x)\n",
    "\n",
    "        preds = model.predict(x)\n",
    "        Xtrain_VGG19.append(preds)\n",
    "        Ytrain_VGG19.append(imageset)\n",
    "\n",
    "        #decode predictions    \n",
    "        Y_top10_VGG19[i] = decode_predictions(preds,top=10)\n",
    "        count += 1\n",
    "\n",
    "#number of images processed\n",
    "print count\n",
    "\n",
    "Xtrain_VGG19=np.array(Xtrain_VGG19)\n",
    "Ytrain_VGG19=np.array(Ytrain_VGG19)\n",
    "Xtrain_VGG19.shape\n",
    "# img_path = 'inputdata/train/SHARK/img_00072.jpg'\n",
    "# img = image.load_img(img_path, target_size=(224, 224))\n",
    "# x = image.img_to_array(img)\n",
    "# x = np.expand_dims(x, axis=0)\n",
    "# x = preprocess_input(x)\n",
    "\n",
    "# block4_pool_features = model.predict(x)\n",
    "# print block4_pool_features.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain_VGG19=np.array(Xtrain_VGG19)\n",
    "Ytrain_VGG19=np.array(Ytrain_VGG19)\n",
    "Xtrain_VGG19.shape\n",
    "\n",
    "Xtrain_VGG19=Xtrain_VGG19.reshape(3777,1000)\n",
    "np.savez('VGG19FeatueExtact',Xtrain_VGG19=Xtrain_VGG19,Ytrain_VGG19=Ytrain_VGG19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YFT\n",
      "SHARK\n",
      "OTHER\n",
      "DOL\n",
      "NoF\n",
      "LAG\n",
      "ALB\n",
      "BET\n",
      "3777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3777, 1, 1000)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Input\n",
    "from keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "Xtrain_InceptionV3=[]\n",
    "Ytrain_InceptionV3=[]\n",
    "count = 0\n",
    "Y_top10_InceptionV3 = {}\n",
    "\n",
    "# this could also be the output a different Keras model or layer\n",
    "input_tensor = Input(shape=(224, 224, 3))  # this assumes K.image_data_format() == 'channels_last'\n",
    "\n",
    "# model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=True)\n",
    "model = InceptionV3(input_tensor=input_tensor,weights='imagenet', include_top=True)\n",
    "\n",
    "#creating normalized image data set\n",
    "for imageset in Allimages.keys():\n",
    "    print imageset\n",
    "    for i in Allimages[imageset]:\n",
    "        img_path = 'inputdata/train/'+imageset+'/'+i\n",
    "        img = image.load_img(img_path, target_size=(224, 224,3))\n",
    "        \n",
    "        x = image.img_to_array(img)\n",
    "        x[:,:,0] = x[:,:,0] - I_R\n",
    "        x[:,:,1] = x[:,:,1] - I_G\n",
    "        x[:,:,2] = x[:,:,2] - I_B\n",
    "    \n",
    "\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "#       x = preprocess_input(x)\n",
    "\n",
    "        preds = model.predict(x)\n",
    "        Xtrain_InceptionV3.append(preds)\n",
    "        Ytrain_InceptionV3.append(imageset)\n",
    "\n",
    "        #decode predictions    \n",
    "        Y_top10_InceptionV3[i] = decode_predictions(preds,top=10)\n",
    "        count += 1\n",
    "\n",
    "#number of images processed\n",
    "print count\n",
    "\n",
    "Xtrain_InceptionV3=np.array(Xtrain_InceptionV3)\n",
    "Ytrain_InceptionV3=np.array(Ytrain_InceptionV3)\n",
    "Xtrain_InceptionV3.shape\n",
    "# img_path = 'inputdata/train/SHARK/img_00072.jpg'\n",
    "# img = image.load_img(img_path, target_size=(224, 224))\n",
    "# x = image.img_to_array(img)\n",
    "# x = np.expand_dims(x, axis=0)\n",
    "# x = preprocess_input(x)\n",
    "\n",
    "# features = model.predict(x)\n",
    "# print features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain_InceptionV3=np.array(Xtrain_InceptionV3)\n",
    "Ytrain_InceptionV3=np.array(Ytrain_InceptionV3)\n",
    "Xtrain_InceptionV3.shape\n",
    "\n",
    "Xtrain_InceptionV3=Xtrain_InceptionV3.reshape(3777,1000)\n",
    "np.savez('InceptionV3FeatueExtact',Xtrain_InceptionV3 = Xtrain_InceptionV3,Ytrain_InceptionV3=Ytrain_InceptionV3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
